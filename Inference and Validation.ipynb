{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference = make predictions\n",
    "# Avoid overfitting through regularization such as dropout\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MINIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MINIST_data', download = True, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from torch import nn, optim\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        n_features = 784\n",
    "        n_hidden = [256, 128, 64]\n",
    "        n_output = 10\n",
    "        self.h1 = nn.Linear(n_features, n_hidden[0])\n",
    "        self.h2 = nn.Linear(n_hidden[0], n_hidden[1])\n",
    "        self.h3 = nn.Linear(n_hidden[1], n_hidden[2])\n",
    "        self.output = nn.Linear(n_hidden[2], n_output)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            \n",
    "            x = self.relu(self.h1(x))\n",
    "            x = self.relu(self.h2(x))\n",
    "            x = self.relu(self.h3(x))\n",
    "            x = self.softmax(self.output(x))\n",
    "\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "model = Classifier()\n",
    "images, labels = next(iter(testloader))\n",
    "# get loss\n",
    "ps = torch.exp(model(images))\n",
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1]) torch.Size([64])\n",
      "torch.Size([64, 64]) torch.Size([64, 1]) torch.Size([64])\n",
      "torch.Size([64, 1])\n",
      "tensor([[4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [2],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4],\n",
      "        [4]]) labels tensor([3, 6, 3, 9, 7, 8, 1, 8, 0, 5, 5, 0, 4, 1, 4]) tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim = 1)\n",
    "#print(top_class[:10,:])\n",
    "#print(top_p[top_class[:10, :]])\n",
    "\n",
    "# to equal the shapes : convert to vector 64,64 from 64,1 and 64\n",
    "print(top_class.shape, labels.shape)\n",
    "equals = top_class == labels\n",
    "print(equals.shape, top_class.shape, labels.shape)\n",
    "#print(top_class[0:10], \"labels\" , labels[0:10], equals[0:10])\n",
    "\n",
    "equals = top_class == labels.view(*top_class.shape)\n",
    "print(equals.shape)\n",
    "print(top_class[0:15], \"labels\" , labels[0:15], equals[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.875%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "# get accuracy of untrained data\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error sum 0.3684121687878678\n",
      "error sum 0.36424563884703337\n",
      "error sum 0.35963521714308366\n",
      "error sum 0.3558622234220952\n",
      "error sum 0.35185300039330014\n",
      "error sum 0.34786177139038216\n",
      "error sum 0.3441995717664517\n",
      "error sum 0.34050450045893443\n",
      "error sum 0.33744214358392044\n",
      "error sum 0.3333165336932455\n",
      "error sum 0.32995239128944465\n",
      "error sum 0.32633348889569486\n",
      "error sum 0.32339180637397236\n",
      "error sum 0.3194832546529231\n",
      "error sum 0.3173463902176062\n",
      "error sum 0.31402613792909995\n",
      "error sum 0.31114578038168106\n",
      "error sum 0.30791513870424553\n",
      "error sum 0.3053410117274154\n",
      "error sum 0.30257028283309073\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "epoch = 8\n",
    "train_error = 0\n",
    "\n",
    "optimizer = optim.SGD( model.parameters(), lr = 0.003)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_error = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad() #restart\n",
    "        \n",
    "        output = model(images) # forward pass\n",
    "        loss = criterion(output, labels) # calculate error\n",
    "        loss.backward() # back pass , get the gradients\n",
    "        \n",
    "        optimizer.step() # update weight\n",
    "        \n",
    "        train_error += loss.item()\n",
    "    else:\n",
    "        print(f'error sum {train_error/len(trainloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error: 0.35815516114234924\n",
      "train error: 0.059776101261377335\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "# check the test data\n",
    "\n",
    "test_error = 0\n",
    "for images, labels in testloader:\n",
    "    output = model(images)\n",
    "    loss = criterion(output, labels)\n",
    "    test_error += loss\n",
    "else:\n",
    "    print(f'test error: {test_error/len(testloader)}')\n",
    "    \n",
    "train_error = 0\n",
    "for images, labels in testloader:\n",
    "    output = model(images)\n",
    "    loss = criterion(output, labels)\n",
    "    train_error += loss\n",
    "else:\n",
    "    print(f'train error: {train_error/len(trainloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping strategy: stop in early step aprox 8 - 10 epochs\n",
    "# Other way is DROP OUT\n",
    "\n",
    "class Clasifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid1 = nn.Linear(784, 256)\n",
    "        self.hid2 = nn.Linear(256, 128)\n",
    "        self.hid3 = nn.Linear(128, 64)\n",
    "        self.out = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "        # dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(self.relu(self.hid1(x)))\n",
    "        x = self.dropout(self.relu(self.hid2(x)))\n",
    "        x = self.dropout(self.relu(self.hid3(x)))\n",
    "        x = self.softmax(self.output(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Dropout only for training to prevent overfitting, no validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with dropout\n",
    "\n",
    "from torch import optim\n",
    "epoch = 8\n",
    "train_error = 0\n",
    "\n",
    "optimizer = optim.SGD( model.parameters(), lr = 0.003)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "    train_error = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad() #restart\n",
    "        \n",
    "        output = model(images) # forward pass\n",
    "        loss = criterion(output, labels) # calculate error\n",
    "        loss.backward() # back pass , get the gradients\n",
    "        \n",
    "        optimizer.step() # update weight\n",
    "        \n",
    "        train_error += loss.item()\n",
    "    else:\n",
    "        print(f'error sum {train_error/len(trainloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mean:\n",
      "\n",
      "mean(...)\n",
      "    .. function:: mean(input) -> Tensor\n",
      "    \n",
      "    Returns the mean value of all elements in the :attr:`input` tensor.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(1, 3)\n",
      "        >>> a\n",
      "        tensor([[ 0.2294, -0.5481,  1.3288]])\n",
      "        >>> torch.mean(a)\n",
      "        tensor(0.3367)\n",
      "    \n",
      "    .. function:: mean(input, dim, keepdim=False, out=None) -> Tensor\n",
      "    \n",
      "    Returns the mean value of each row of the :attr:`input` tensor in the given\n",
      "    dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "    reduce over all of them.\n",
      "    \n",
      "    \n",
      "    If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "    as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "    Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "    output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor\n",
      "        dim (int or tuple of ints): the dimension or dimensions to reduce\n",
      "        keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "        out (Tensor): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4, 4)\n",
      "        >>> a\n",
      "        tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
      "                [-0.9644,  1.0131, -0.6549, -1.4279],\n",
      "                [-0.2951, -1.3350, -0.7694,  0.5600],\n",
      "                [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
      "        >>> torch.mean(a, 1)\n",
      "        tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
      "        >>> torch.mean(a, 1, True)\n",
      "        tensor([[-0.0163],\n",
      "                [-0.5085],\n",
      "                [-0.4599],\n",
      "                [ 0.1807]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use model.eval() to turn off dropout, return turn on with model.train()\n",
    "test_error = 0\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        test_error += loss\n",
    "    else:\n",
    "        print(f'test error: {test_error/len(testloader)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
